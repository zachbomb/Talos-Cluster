# yaml-language-server: $schema=https://kubernetes-schemas.pages.dev/helm.toolkit.fluxcd.io/helmrelease_v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: ollama
  namespace: ollama
spec:
  releaseName: ollama
  interval: 15m
  timeout: 10m
  chart:
    spec:
      chart: ollama
      version: 8.14.0
      sourceRef:
        kind: HelmRepository
        name: truecharts
        namespace: flux-system
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  values:
    image:
      repository: docker.io/ollama/ollama
      pullPolicy: IfNotPresent
      tag: 0.12.5@sha256:e43c26d2d1ebc726bc932166d2979086310b2f9c5ccd64fb06b55d1ea2c4f2cc
    rocmImage:
      repository: docker.io/ollama/ollama
      pullPolicy: IfNotPresent
      tag: 0.12.5-rocm@sha256:212f5b789505500df5cc4d229da318b02df04fab4cb7a0286a2c014de9d823f0
    uiImage:
      repository: ghcr.io/open-webui/open-webui
      pullPolicy: IfNotPresent
      tag: latest@sha256:f43e2e1ac4634bb26912c4cc1eb167f0431cabda8f65f2d2457a615def982fdc
    credentials:
      s3:
        type: s3
        url: ${S3URL}
        bucket: "${S3PREFIX}-ollama"
        accessKey: ${S3ID}
        secretKey: ${S3KEY}
        encrKey: ${S3KEY}
    ingress:
      main:
        enabled: true
        hosts:
          - host: ollama.${BASE_DOMAIN}
            paths:
              - path: /
                pathType: Prefix
        integrations:
          nginx:
            enabled: true
            ingressClassName: internal
          traefik:
            enabled: false
            middlewares:
              - name: local
                namespace: traefik
          certManager:
            enabled: true
            certificateIssuer: wethecommon-prod-cert
          homepage:
            enabled: true
            name: Ollama
            description: AI Language Model
            group: Lifestyle & Home
            widget:
              enabled: false
    service:
      main:
        enabled: true
        type: LoadBalancer
        loadBalancerIP: ${OLLAMA_IP}
        ports:
          main:
            enabled: true
            port: 10686
            targetPort: 10686
            protocol: tcp
          api:
            enabled: true
            port: 11434
            targetPort: 11434
            protocol: tcp
      api:
        enabled: false
    ollama:
      registration:
        enabled: true
        def_user_role: "pending"
      whisper:
        model: "base"
      rag:
        model_device_type: "cpu"
        model: "all-MiniLM-L6-v2"
    workload:
      main:
        podSpec:
          containers:
            main:
              imageSelector: image
              probes:
                liveness:
                  enabled: true
                  type: http
                  path: /api/version
                  port: 11434
                readiness:
                  enabled: true
                  type: http
                  path: /api/version
                  port: 11434
                startup:
                  enabled: true
                  type: tcp
                  port: 11434
      ui:
        enabled: true
        type: Deployment
        podSpec:
          containers:
            ui:
              primary: true
              enabled: true
              imageSelector: uiImage
              probes:
                liveness:
                  enabled: true
                  type: http
                  path: /
                  port: 10686
                readiness:
                  enabled: true
                  type: http
                  path: /
                  port: 10686
                startup:
                  enabled: true
                  type: tcp
                  port: 10686
              env:
                PORT: "10686"
                OLLAMA_BASE_URL: "http://ollama-api:11434"
                ENABLE_SIGNUP: "true"
                DEFAULT_USER_ROLE: "pending"
                WHISPER_MODEL: "base"
                RAG_EMBEDDING_MODEL: "all-MiniLM-L6-v2"
                RAG_EMBEDDING_MODEL_DEVICE_TYPE: "cpu"
                WEBUI_SECRET_KEY:
                  secretKeyRef:
                    name: ollama-secrets
                    key: WEBUI_SECRET_KEY
    configmap:
      tcportal-open:
        enabled: true
        data:
          placeholder: "enabled"
    persistence:
      config:
        enabled: true
        mountPath: /root/.ollama
        volsync:
          - name: config
            type: restic
            credentials: s3
            src:
              enabled: true
            dest:
              enabled: true
      data:
        enabled: true
        mountPath: /app/backend/data
        volsync:
          - name: data
            type: restic
            credentials: s3
            src:
              enabled: true
            dest:
              enabled: true
    autoscaling:
      vpa:
        enabled: true
